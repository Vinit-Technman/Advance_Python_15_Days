{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>\n",
    "WEB SCRAPING WITH PYTHON\n",
    "</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bs4\n",
      "  Obtaining dependency information for bs4 from https://files.pythonhosted.org/packages/51/bb/bf7aab772a159614954d84aa832c129624ba6c32faa559dfb200a534e50b/bs4-0.0.2-py2.py3-none-any.whl.metadata\n",
      "  Downloading bs4-0.0.2-py2.py3-none-any.whl.metadata (411 bytes)\n",
      "Collecting beautifulsoup4 (from bs4)\n",
      "  Obtaining dependency information for beautifulsoup4 from https://files.pythonhosted.org/packages/b1/fe/e8c672695b37eecc5cbf43e1d0638d88d66ba3a44c4d321c796f4e59167f/beautifulsoup4-4.12.3-py3-none-any.whl.metadata\n",
      "  Downloading beautifulsoup4-4.12.3-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting soupsieve>1.2 (from beautifulsoup4->bs4)\n",
      "  Obtaining dependency information for soupsieve>1.2 from https://files.pythonhosted.org/packages/4c/f3/038b302fdfbe3be7da016777069f26ceefe11a681055ea1f7817546508e3/soupsieve-2.5-py3-none-any.whl.metadata\n",
      "  Downloading soupsieve-2.5-py3-none-any.whl.metadata (4.7 kB)\n",
      "Downloading bs4-0.0.2-py2.py3-none-any.whl (1.2 kB)\n",
      "Downloading beautifulsoup4-4.12.3-py3-none-any.whl (147 kB)\n",
      "   ---------------------------------------- 0.0/147.9 kB ? eta -:--:--\n",
      "   -- ------------------------------------- 10.2/147.9 kB ? eta -:--:--\n",
      "   ------------------------ --------------- 92.2/147.9 kB 1.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 147.9/147.9 kB 1.3 MB/s eta 0:00:00\n",
      "Downloading soupsieve-2.5-py3-none-any.whl (36 kB)\n",
      "Installing collected packages: soupsieve, beautifulsoup4, bs4\n",
      "Successfully installed beautifulsoup4-4.12.3 bs4-0.0.2 soupsieve-2.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lxml\n",
      "  Obtaining dependency information for lxml from https://files.pythonhosted.org/packages/58/16/99b03974974537c8c786fb98183d7c213ceb16e71205174a29ae869ca988/lxml-5.2.2-cp312-cp312-win_amd64.whl.metadata\n",
      "  Downloading lxml-5.2.2-cp312-cp312-win_amd64.whl.metadata (3.5 kB)\n",
      "Downloading lxml-5.2.2-cp312-cp312-win_amd64.whl (3.8 MB)\n",
      "   ---------------------------------------- 0.0/3.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/3.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/3.8 MB 660.6 kB/s eta 0:00:06\n",
      "    --------------------------------------- 0.1/3.8 MB 871.5 kB/s eta 0:00:05\n",
      "   -- ------------------------------------- 0.3/3.8 MB 1.7 MB/s eta 0:00:03\n",
      "   -------- ------------------------------- 0.8/3.8 MB 3.8 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 1.5/3.8 MB 6.2 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 2.7/3.8 MB 9.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  3.8/3.8 MB 12.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 3.8/3.8 MB 11.1 MB/s eta 0:00:00\n",
      "Installing collected packages: lxml\n",
      "Successfully installed lxml-5.2.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Home - Technman\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'\n",
    "}\n",
    "\n",
    "\n",
    "page = requests.get(\"https://technmanconsulting.com\",headers=headers)\n",
    "\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "title = soup.title.text\n",
    "# print(soup.h1)\n",
    "print(f\"Title: {title}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting selenium\n",
      "  Obtaining dependency information for selenium from https://files.pythonhosted.org/packages/e0/7a/08f0ea19a0c835e88aad011083d9dda69a9dfa4585c3453b3bd842eb7bed/selenium-4.21.0-py3-none-any.whl.metadata\n",
      "  Downloading selenium-4.21.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: urllib3[socks]<3,>=1.26 in c:\\users\\vinit\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from selenium) (2.0.7)\n",
      "Collecting trio~=0.17 (from selenium)\n",
      "  Obtaining dependency information for trio~=0.17 from https://files.pythonhosted.org/packages/76/51/12d78ec8abcbda51d8f115d98ebd3ee3da9d9d9af00ac69d3097c5b8d51a/trio-0.25.1-py3-none-any.whl.metadata\n",
      "  Downloading trio-0.25.1-py3-none-any.whl.metadata (8.7 kB)\n",
      "Collecting trio-websocket~=0.9 (from selenium)\n",
      "  Obtaining dependency information for trio-websocket~=0.9 from https://files.pythonhosted.org/packages/48/be/a9ae5f50cad5b6f85bd2574c2c923730098530096e170c1ce7452394d7aa/trio_websocket-0.11.1-py3-none-any.whl.metadata\n",
      "  Downloading trio_websocket-0.11.1-py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\vinit\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from selenium) (2024.2.2)\n",
      "Requirement already satisfied: typing_extensions>=4.9.0 in c:\\users\\vinit\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from selenium) (4.10.0)\n",
      "Collecting attrs>=23.2.0 (from trio~=0.17->selenium)\n",
      "  Obtaining dependency information for attrs>=23.2.0 from https://files.pythonhosted.org/packages/e0/44/827b2a91a5816512fcaf3cc4ebc465ccd5d598c45cefa6703fcf4a79018f/attrs-23.2.0-py3-none-any.whl.metadata\n",
      "  Downloading attrs-23.2.0-py3-none-any.whl.metadata (9.5 kB)\n",
      "Collecting sortedcontainers (from trio~=0.17->selenium)\n",
      "  Obtaining dependency information for sortedcontainers from https://files.pythonhosted.org/packages/32/46/9cb0e58b2deb7f82b84065f37f3bffeb12413f947f9388e4cac22c4621ce/sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: idna in c:\\users\\vinit\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from trio~=0.17->selenium) (3.6)\n",
      "Collecting outcome (from trio~=0.17->selenium)\n",
      "  Obtaining dependency information for outcome from https://files.pythonhosted.org/packages/55/8b/5ab7257531a5d830fc8000c476e63c935488d74609b50f9384a643ec0a62/outcome-1.3.0.post0-py2.py3-none-any.whl.metadata\n",
      "  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting sniffio>=1.3.0 (from trio~=0.17->selenium)\n",
      "  Obtaining dependency information for sniffio>=1.3.0 from https://files.pythonhosted.org/packages/e9/44/75a9c9421471a6c4805dbf2356f7c181a29c1879239abab1ea2cc8f38b40/sniffio-1.3.1-py3-none-any.whl.metadata\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting cffi>=1.14 (from trio~=0.17->selenium)\n",
      "  Obtaining dependency information for cffi>=1.14 from https://files.pythonhosted.org/packages/e9/63/e285470a4880a4f36edabe4810057bd4b562c6ddcc165eacf9c3c7210b40/cffi-1.16.0-cp312-cp312-win_amd64.whl.metadata\n",
      "  Downloading cffi-1.16.0-cp312-cp312-win_amd64.whl.metadata (1.5 kB)\n",
      "Collecting wsproto>=0.14 (from trio-websocket~=0.9->selenium)\n",
      "  Obtaining dependency information for wsproto>=0.14 from https://files.pythonhosted.org/packages/78/58/e860788190eba3bcce367f74d29c4675466ce8dddfba85f7827588416f01/wsproto-1.2.0-py3-none-any.whl.metadata\n",
      "  Downloading wsproto-1.2.0-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting pysocks!=1.5.7,<2.0,>=1.5.6 (from urllib3[socks]<3,>=1.26->selenium)\n",
      "  Obtaining dependency information for pysocks!=1.5.7,<2.0,>=1.5.6 from https://files.pythonhosted.org/packages/8d/59/b4572118e098ac8e46e399a1dd0f2d85403ce8bbaad9ec79373ed6badaf9/PySocks-1.7.1-py3-none-any.whl.metadata\n",
      "  Downloading PySocks-1.7.1-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting pycparser (from cffi>=1.14->trio~=0.17->selenium)\n",
      "  Obtaining dependency information for pycparser from https://files.pythonhosted.org/packages/13/a3/a812df4e2dd5696d1f351d58b8fe16a405b234ad2886a0dab9183fb78109/pycparser-2.22-py3-none-any.whl.metadata\n",
      "  Downloading pycparser-2.22-py3-none-any.whl.metadata (943 bytes)\n",
      "Collecting h11<1,>=0.9.0 (from wsproto>=0.14->trio-websocket~=0.9->selenium)\n",
      "  Obtaining dependency information for h11<1,>=0.9.0 from https://files.pythonhosted.org/packages/95/04/ff642e65ad6b90db43e668d70ffb6736436c7ce41fcc549f4e9472234127/h11-0.14.0-py3-none-any.whl.metadata\n",
      "  Using cached h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Downloading selenium-4.21.0-py3-none-any.whl (9.5 MB)\n",
      "   ---------------------------------------- 0.0/9.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/9.5 MB 991.0 kB/s eta 0:00:10\n",
      "   ---------------------------------------- 0.1/9.5 MB 1.1 MB/s eta 0:00:09\n",
      "    --------------------------------------- 0.2/9.5 MB 1.8 MB/s eta 0:00:06\n",
      "   -- ------------------------------------- 0.6/9.5 MB 2.9 MB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 1.2/9.5 MB 5.4 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 2.2/9.5 MB 7.9 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 3.4/9.5 MB 10.8 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 4.1/9.5 MB 12.5 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 5.3/9.5 MB 13.0 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 6.0/9.5 MB 13.7 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 6.0/9.5 MB 13.7 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 6.6/9.5 MB 12.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.5/9.5 MB 15.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 9.5/9.5 MB 14.7 MB/s eta 0:00:00\n",
      "Downloading trio-0.25.1-py3-none-any.whl (467 kB)\n",
      "   ---------------------------------------- 0.0/467.7 kB ? eta -:--:--\n",
      "   --------------------------------------- 467.7/467.7 kB 28.6 MB/s eta 0:00:00\n",
      "Downloading trio_websocket-0.11.1-py3-none-any.whl (17 kB)\n",
      "Downloading attrs-23.2.0-py3-none-any.whl (60 kB)\n",
      "   ---------------------------------------- 0.0/60.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 60.8/60.8 kB 3.2 MB/s eta 0:00:00\n",
      "Downloading cffi-1.16.0-cp312-cp312-win_amd64.whl (181 kB)\n",
      "   ---------------------------------------- 0.0/182.0 kB ? eta -:--:--\n",
      "   --------------------------------------- 182.0/182.0 kB 11.4 MB/s eta 0:00:00\n",
      "Downloading PySocks-1.7.1-py3-none-any.whl (16 kB)\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
      "Downloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
      "Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
      "Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Downloading pycparser-2.22-py3-none-any.whl (117 kB)\n",
      "   ---------------------------------------- 0.0/117.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 117.6/117.6 kB 6.7 MB/s eta 0:00:00\n",
      "Installing collected packages: sortedcontainers, sniffio, pysocks, pycparser, h11, attrs, wsproto, outcome, cffi, trio, trio-websocket, selenium\n",
      "Successfully installed attrs-23.2.0 cffi-1.16.0 h11-0.14.0 outcome-1.3.0.post0 pycparser-2.22 pysocks-1.7.1 selenium-4.21.0 sniffio-1.3.1 sortedcontainers-2.4.0 trio-0.25.1 trio-websocket-0.11.1 wsproto-1.2.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scrape data from a website with dynamic content (using Selenium)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scrape data from a website and save it as a CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Obtaining dependency information for pandas from https://files.pythonhosted.org/packages/22/a5/a0b255295406ed54269814bc93723cfd1a0da63fb9aaf99e1364f07923e5/pandas-2.2.2-cp312-cp312-win_amd64.whl.metadata\n",
      "  Downloading pandas-2.2.2-cp312-cp312-win_amd64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\vinit\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\vinit\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Obtaining dependency information for pytz>=2020.1 from https://files.pythonhosted.org/packages/9c/3d/a121f284241f08268b21359bd425f7d4825cffc5ac5cd0e1b3d82ffd2b10/pytz-2024.1-py2.py3-none-any.whl.metadata\n",
      "  Using cached pytz-2024.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Obtaining dependency information for tzdata>=2022.7 from https://files.pythonhosted.org/packages/65/58/f9c9e6be752e9fcb8b6a0ee9fb87e6e7a1f6bcab2cdc73f02bb7ba91ada0/tzdata-2024.1-py2.py3-none-any.whl.metadata\n",
      "  Using cached tzdata-2024.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\vinit\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Downloading pandas-2.2.2-cp312-cp312-win_amd64.whl (11.5 MB)\n",
      "   ---------------------------------------- 0.0/11.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/11.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/11.5 MB 653.6 kB/s eta 0:00:18\n",
      "    --------------------------------------- 0.2/11.5 MB 2.0 MB/s eta 0:00:06\n",
      "   - -------------------------------------- 0.5/11.5 MB 3.3 MB/s eta 0:00:04\n",
      "   --- ------------------------------------ 1.1/11.5 MB 5.7 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 2.2/11.5 MB 9.2 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 3.3/11.5 MB 11.7 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 4.5/11.5 MB 13.5 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 4.5/11.5 MB 13.5 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 7.0/11.5 MB 16.5 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 8.1/11.5 MB 17.8 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 9.8/11.5 MB 18.9 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 11.0/11.5 MB 26.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.5/11.5 MB 26.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.5/11.5 MB 23.4 MB/s eta 0:00:00\n",
      "Using cached pytz-2024.1-py2.py3-none-any.whl (505 kB)\n",
      "Using cached tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
      "Installing collected packages: pytz, tzdata, pandas\n",
      "Successfully installed pandas-2.2.2 pytz-2024.1 tzdata-2024.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Title': 'Dollars and Dreams: 10 Hottest Professions for Hefty Paychecks', 'Body': 'Stay ahead of the curve. Traditional career paths are transforming, and new opportunities are emerging.'}, {'Title': 'IS LEARNING PYTHON WORTH IT?', 'Body': 'Python is a popular programming language that is straightforward to use and apprehend. It lets'}, {'Title': '“Cybersecurity in the Digital Age: Protecting Your Business from Emerging Threats”', 'Body': 'In the present reliably influencing modernized world, online security has transformed into an essential concern'}, {'Title': 'Unlocking Success: Strategies to Boost Performance and Efficiency in IT Infrastructure', 'Body': 'Procedures to Lift Execution and Productivity in Your IT Foundation: Hello there, individual tech lovers!'}, {'Title': 'Streamlining Business Operations: The Role of Technology Consulting', 'Body': 'Introduction: In the present quickly developing business climate, ventures experience heightening requests to refine their'}, {'Title': 'The Role of Big Data Analytics in Decision-Making', 'Body': 'Presentation: In the computerized age, where information fills in as the key part of development,'}, {'Title': 'Success Unveiled: The Precision Path to OPT and CPT Excellence', 'Body': 'Leaving on the groundbreaking excursion of Discretionary Pragmatic Preparation (Pick) and Curricular Down to earth'}, {'Title': 'Java Developer Certification Prep: A Roadmap to Exam Success', 'Body': 'Introduction: In the dynamic landscape of software development, a Java developer training and placement certification'}, {'Title': 'Cloud Security Mastery: Enhance Your Expertise with AWS Training', 'Body': 'Introduction: \\xa0 In our consistently impacting computerized world, shielding advanced resources through the security of'}]\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'\n",
    "}\n",
    "\n",
    "\n",
    "res = requests.get(\"https://technmanconsulting.com/blogs/\",headers=headers)\n",
    "\n",
    "if res.status_code==200:\n",
    "    soup = BeautifulSoup(res.content, 'html.parser')\n",
    "    articles=soup.find_all('article')\n",
    "    data=[]\n",
    "    titles=soup.find_all('h3',class_='elementor-post__title')\n",
    "    for i in articles:\n",
    "        # data.append(i.get_text())\n",
    "        soup2=i.find('h3')\n",
    "        # print(soup2)\n",
    "        data.append(\n",
    "            {\n",
    "                'Title' : soup2.get_text().strip(),\n",
    "                'Body' : i.find('p').get_text().strip()\n",
    "             }\n",
    "        )\n",
    "\n",
    "    df=pd.DataFrame(data)\n",
    "    df.to_csv('Blogs.csv',index=False)\n",
    "    print(data)\n",
    "else:\n",
    "    print(f\"Failed to retrieve the page. Status code: {res.status_code}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement a program that scrapes product details (name, \n",
    "price, description) from an e-commerce website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'title': 'Toshiba Porteg...', 'price': '$1203.41', 'desc': 'Toshiba Portege X30-D-10J Black/Blue, 13.3\" FHD IPS, Core i5-7200U, 8GB, 256GB SSD, Windows 10 Pro'}\n",
      "{'title': 'Lenovo V110-15...', 'price': '$321.94', 'desc': 'Lenovo V110-15IAP, 15.6\" HD, Celeron N3350 1.1GHz, 4GB, 128GB SSD, Windows 10 Home'}\n",
      "{'title': 'Iphone', 'price': '$899.99', 'desc': 'Silver'}\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "}\n",
    "\n",
    "\n",
    "res = requests.get(\"https://www.webscraper.io/test-sites/e-commerce/allinone\",headers=headers)\n",
    "data=[]\n",
    "if res.status_code==200:\n",
    "    soup = BeautifulSoup(res.content, 'html.parser')\n",
    "    # print(soup.find_all('div',class_='product-wrapper'))\n",
    "    products=soup.find_all('div',class_='product-wrapper')\n",
    "    for i in products:\n",
    "        # print(i.find_all('h4'))\n",
    "        data.append(\n",
    "            {\n",
    "                'title':i.find('a',class_='title').get_text(),\n",
    "                'price':i.find('h4',class_='price').get_text(),\n",
    "                'desc':i.find('p',class_='description').get_text()\n",
    "            }\n",
    "        )\n",
    "for i in data:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a Python program that scrapes news headlines and \n",
    "summaries from a news website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'headlines': 'Prashant Kishor predicts these 4 big changes in Modi 3.0', 'summary': 'Political strategist Prashant Kishor, in an exclusive interview with India Today, predicted a greater concentration of both power and resources with the Centre in Modi 3.0.'}\n",
      "{'headlines': '3 Indians were aboard Singapore Airlines flight hit by ‘extreme turbulence’', 'summary': 'Singapore Airline mentions that there were a total of 211 passengers and 18 crew onboard the flight. Of the 211 passengers, three are from India.'}\n",
      "{'headlines': 'Tamil YouTuber’s gender reveal party for unborn baby lands him in legal trouble', 'summary': \"The gender reveal party, along with the YouTuber and his wife's Dubai trip, was documented in vlogs on his YouTube channel, which boasts 4.28 million subscribers.\"}\n",
      "{'headlines': \"2 cars, 4 cities, new SIM card: How Pune teen driver's father tried to evade cops\", 'summary': 'Vishal Agarwal, father of minor who crashed his Porsche into a bike, hatched an elaborate escape plan to misdirect cops and evade arrest. '}\n",
      "{'headlines': \"How a boy from Barabanki changed course of Iran's history\", 'summary': 'The Shah of Iran was overthrown in 1979 and the liberal Islamic country turned into a hardline Shia theocratic state. Ruhollah Khomeini, who led the 1979 Revolution, was the grandson of Syed Ahmad Musavi Hindi, who went to Iran from Barabanki in Uttar Pradesh, and changed the course of Iranian history forever.'}\n",
      "{'headlines': \"Arvind Kejriwal campaigns for Kanhaiya Kumar in Delhi: 'Defeat Rinkiya Ke Papa'\", 'summary': 'Arvind Kejriwal campaigned for INDIA bloc candidate Kanhaiya Kumar in North East Delhi and urged voters to defeat \"Rinkiya Ke Papa\" in the upcoming Lok Sabha elections.'}\n",
      "{'headlines': 'KKR storm into 4th final after Mitchell Starc decimates SRH', 'summary': 'IPL 2024, Qualifier 1: KKR defeated SRH by 8 wickets to reach the final of the Indian Premier League 2024. SRH will now play the winner of the Eliminator between RR and RCB for a second chance to reach the final.\\r\\n'}\n",
      "{'headlines': 'Bomb threat emails sent to 150 schools in Delhi traced to Budapest: Sources', 'summary': 'The IP address of these bomb threat emails has been traced to Budapest and Delhi Police will\\xa0soon be\\xa0contacting its counterpart in Hungary for further investigation.'}\n",
      "{'headlines': 'Rhino home gets a Modi boost', 'summary': \"Assam's Kaziranga National Park has extended its closing dates for the first time due to a surge in tourist arrivals. Kaziranga officials, tour guides and transport operators say Prime Minister Narendra Modi's visit to the park has significantly boosted the its profile and revenue.\"}\n",
      "{'headlines': 'USA stun Bangladesh for historic win in T20I series opener in Houston', 'summary': 'USA vs Bangladesh, 1st T20I: Former New Zealand all-rounder Corey Anderson and former India U19 star Harmeet Singh shone for USA as the hosts hammered Bangladesh in the first of a 3-match T20I series in Houston on Tuesday. '}\n",
      "{'headlines': 'Breakfast was being served, turbulence hit: Horror on Singapore Airlines flight', 'summary': 'A video of the inside of the aircraft after it made an emergency landing shows dented overhead bins, food items strewn on the floor, and oxygen masks and fan panels hanging off the ceiling.\\xa0'}\n",
      "{'headlines': \"Rahul Gandhi's dig at PM over bail to Pune teen driver: 'Justice rests on wealth'\", 'summary': \"Rahul Gandhi cited 'special treatment' given to teen boy who killed a couple by ramming his Porche car into the bike they were riding in Pune on Sunday. \"}\n",
      "{'headlines': 'Anant Ambani-Radhika Merchant’s wedding countdown to begin on May 29 in Italy', 'summary': \"Anant Ambani and Radhika Merchant's pre-wedding cruise party will host Bollywood's biggest stars, apart from global dignitaries. The party, with a no-phone policy, will start in Italy on May 29, and conclude in Switzerland on June 1.\"}\n",
      "{'headlines': \"Poll analyst Prashant Kishor predicts 300 seats for BJP: 'No anger against PM'\", 'summary': 'While speaking exclusively to India Today TV, political analyst Prashant Kishor predicted that the BJP is most likely to repeat its 2019 performance and would get around 300 seats in the 2024 Lok Sabha elections. '}\n",
      "{'headlines': 'Liquid nitrogen paan leads to hole in 12-year-old girl’s stomach in Bengaluru', 'summary': 'The doctors at Bengaluru hospital diagnosed the girl with perforation peritonitis, a serious condition involving a hole in her stomach.'}\n",
      "{'headlines': 'What top netas’ rallies, speeches tell us about Lok Sabha polls 2024', 'summary': 'PM Narendra Modi has held double the number of public meetings addressed by his rival Rahul Gandhi during the five phases of the ensuing elections.'}\n",
      "{'headlines': 'Make me something, Sonam Kapoor asks Nancy Tyagi after stunning Cannes debut', 'summary': \"Sonam Kapoor, impressed by Nancy Tyagi's Cannes ensembles, asked the influencer to make an outfit for her. Nancy, who represented India at Cannes with two outfits she designed and stitched herself, responded to the request.\"}\n",
      "{'headlines': 'With mother still in hospital, Gurbaz joins KKR ‘family’ in IPL 2024 playoffs', 'summary': \"KKR's Rahmanullah Gurbaz has revealed that his mother is still recovering in hospital and he decided to come back early as his team needed help after the departure of Phil Salt. \"}\n",
      "{'headlines': 'Fancy food in India loves liquid nitrogen, but wrong use can cause serious harm', 'summary': \"As a 12-year-old Bengaluru girl develops a hole in her stomach after eating 'smoke paan', here's what health experts want you to know about consuming foods created using liquid nitrogen. \"}\n",
      "{'headlines': 'Pune Porsche crash: Bar which served liquor to juvenile before accident sealed', 'summary': 'The bar which served liquor to the juvenile before he met with an accident, killing two persons, has been sealed by the Pune excise department. The bar owner has also been arrested. '}\n",
      "{'headlines': \"Are you an IDIOT? Yes, it's a real condition\", 'summary': 'Receiving health diagnoses and medication information from online sources has led to the rise of the condition called IDIOT syndrome.'}\n",
      "{'headlines': \"Donald Trump's lawyers rest hush money trial case without calling him to testify\", 'summary': 'Donald Trump is accused of covering up a $130,000 payment that bought the silence of adult star Stormy Daniels, who in the final weeks of the 2016 presidential election was peddling her story of a sexual encounter with the former US President. '}\n",
      "{'headlines': \"Prashant Kishor on what ails Congress: 'Ignorance, laziness, arrogance'\", 'summary': \"Prashant Kishor said that the Congress's condition is like someone who first needs to realise that they lack something and need to work on it in order to improve.  \"}\n",
      "{'headlines': 'UK man dead in severe turbulence on Singapore Airlines flight, 7 critical', 'summary': 'The Boeing 777-300ER plane with 211 passengers and 18 crew was headed to Singapore when it made the emergency landing, the airline said in a statement.'}\n",
      "{'headlines': 'Bhumi Pednekar installs water bowls for animals to protect them from heat', 'summary': \"Bhumi Pednekar was seen installing water bowls in Mumbai's Versova for animals and birds to protect them from the summer heat. Apart from acting, the actor is known for her philanthropic activities. \"}\n",
      "{'headlines': \"Shahana Goswami, Sandhya Suri's 'Santosh' premieres at Cannes 2024\", 'summary': \"Sandhya Suri's crime drama 'Santosh' featuring Shahana Goswami and Sunita Rajwar made a debut at the 77th Cannes Film Festival. \"}\n",
      "{'headlines': \"'Yeh Rishta…' actor Mohena Kumari Singh welcomes 2nd child\", 'summary': \"Former 'Yeh Rishta Kya Kehlata Hai' actor Mohena Kumari Singh welcomed her second child, a baby girl. She and her husband Suyesh Rawat had their first child, a baby boy named Ayaansh, in 2022.\"}\n",
      "{'headlines': 'Uncle Samsik Review: Sang Kang-ho drama can pass off as history lecture', 'summary': \"'Parasite' star Sang Kang-ho features in the new Disney Plus series, 'Uncle Samsik.' Dense with historical and political references, it is currently streaming on Disney Plus Hotstar in India. \"}\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "}\n",
    "\n",
    "\n",
    "res = requests.get(\"https://www.indiatoday.in/\",headers=headers)\n",
    "data=[]\n",
    "if res.status_code==200:\n",
    "    soup = BeautifulSoup(res.content, 'html.parser')\n",
    "    articles=soup.find_all('article')\n",
    "    for i in articles:\n",
    "        data.append(\n",
    "            {\n",
    "                'headlines':i.find('h2').get_text(),\n",
    "                'summary':i.find('div',class_='B1S3_story__shortcont__inicf').get_text()\n",
    "            }\n",
    "        )\n",
    "        # print(i)\n",
    "for i in data:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'title': 'Java Developer', 'company': 'AskMeOffers', 'location': 'Work from home'}\n",
      "{'title': 'Artificial Intelligence (AI) Associate', 'company': 'AskMeOffers', 'location': 'Work from home'}\n",
      "{'title': 'Software Developer', 'company': 'AskMeOffers', 'location': 'Work from home'}\n",
      "{'title': 'C/C++ Developer', 'company': 'AskMeOffers', 'location': 'Work from home'}\n",
      "{'title': 'SAP BASIS', 'company': 'AskMeOffers', 'location': 'Work from home'}\n",
      "{'title': '.NET Developer', 'company': 'AskMeOffers', 'location': 'Work from home'}\n",
      "{'title': 'Java Developer', 'company': 'AskMeOffers', 'location': 'Work from home'}\n",
      "{'title': 'Software Developer', 'company': 'Home Shiksha', 'location': 'Hyderabad                                            (Hybrid)'}\n",
      "{'title': 'Junior Software Developer', 'company': 'Transasia Bio Medicals Limited', 'location': 'Mumbai, Pune'}\n",
      "{'title': 'UI/ UX Designer', 'company': 'MAZIK TECH SOLUTIONS PRIVATE LIMITED', 'location': 'Hyderabad'}\n",
      "{'title': 'Head Of Engineering', 'company': 'HyrEzy Talent Solutions LLP', 'location': 'Bangalore'}\n",
      "{'title': 'DevOps And Blockchain', 'company': 'Mazenet Solution', 'location': 'Chennai, Delhi, Pune'}\n",
      "{'title': 'SFCC Backend Architect', 'company': 'Toolify Private Limited', 'location': 'Gurgaon, Pune, Hyderabad, Noida'}\n",
      "{'title': 'SFCC Backend Architect', 'company': 'Toolify Private Limited', 'location': 'Hyderabad, Noida, Pune, Gurgaon'}\n",
      "{'title': 'SFCC Backend Architect', 'company': 'Toolify Private Limited', 'location': 'Noida, Hyderabad, Pune, Gurgaon'}\n",
      "{'title': 'PFMEA & AIAG - VDA Latest Version', 'company': 'Mazenet Solution', 'location': 'Noida'}\n",
      "{'title': 'Tibco Flogo', 'company': 'Mazenet Solution', 'location': 'Chennai, Delhi, Bangalore'}\n",
      "{'title': 'Cisco DNA & Aruba', 'company': 'Mazenet Solution', 'location': 'Chennai, Delhi, Pune, Hyderabad, Bangalore'}\n",
      "{'title': 'Cybersecurity Trainers Or Consultant', 'company': 'Mazenet Solution', 'location': 'Palghar, Thane, Mumbai'}\n",
      "{'title': 'Freelance GitHub Trainer', 'company': 'Irizpro Learning Solution', 'location': 'Thane, Mumbai'}\n",
      "{'title': 'Sr Power Platform Development Architect', 'company': 'True Blue HR Consultants', 'location': 'Bangalore'}\n",
      "{'title': 'Oracle Cloud Infrastructure Manager', 'company': 'Informica Solutions', 'location': 'Bangalore'}\n",
      "{'title': 'Full-Stack Development', 'company': 'Toolify Private Limited', 'location': 'Work from home'}\n",
      "{'title': 'AI/ML Manager', 'company': 'Vs Placement Services', 'location': 'Work from home'}\n",
      "{'title': 'Java Technical Lead', 'company': 'HRM INFO', 'location': 'Pune, Bangalore'}\n",
      "{'title': 'Technical Program Manager', 'company': 'Career Fair Services & Technology', 'location': 'Work from home'}\n",
      "{'title': 'Java Microservices', 'company': 'VIBRANT STAFFING SOLUTIONS PVT LTD', 'location': 'Chennai'}\n",
      "{'title': 'Data Scientist', 'company': 'Mazenet Solution', 'location': 'Pune'}\n",
      "{'title': 'Mulesoft Architect', 'company': 'Prointegrate', 'location': 'Bangalore'}\n",
      "{'title': 'GM- IT ERP- Mumbai', 'company': 'Corporate Chemistry', 'location': 'Mumbai'}\n",
      "{'title': 'Windchill Solutions Architect', 'company': 'Vizlogic Digital Solutions Private Limited', 'location': 'Chennai, Mumbai'}\n",
      "{'title': 'Solutions Architect', 'company': 'Vs Placement Services', 'location': 'Work from home'}\n",
      "{'title': 'Product Manager - Bangalore', 'company': 'True Blue HR Consultants', 'location': 'Bangalore'}\n",
      "{'title': 'Solutions Architect', 'company': 'Career Fair Services & Technology', 'location': 'Work from home'}\n",
      "{'title': 'Solutions Architect', 'company': 'Career Fair Services & Technology', 'location': 'Work from home'}\n",
      "{'title': 'Sr Azure Infrastructure Architect - 15+ Years', 'company': 'True Blue HR Consultants', 'location': 'Bangalore'}\n",
      "{'title': 'SAP S4 HANA SD Consultant And Project Lead', 'company': 'VIBRANT STAFFING SOLUTIONS PVT LTD', 'location': 'Bangalore'}\n",
      "{'title': 'Tehcnilca Program Manager', 'company': 'Vs Placement Services', 'location': 'Work from home'}\n",
      "{'title': 'Information Technology Security Engineer', 'company': 'Informica Solutions', 'location': 'Bangalore'}\n",
      "{'title': 'Digital Infrastructure Head', 'company': 'Spring HR', 'location': 'Ahmedabad, Gandhinagar, Jamnagar, Vadodara'}\n"
     ]
    }
   ],
   "source": [
    "# https://in.indeed.com/jobs?q=&l=Ahmedabad%2C+Gujarat&from=searchOnHP&vjk=a171eb8abeb40eee\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "}\n",
    "\n",
    "\n",
    "res = requests.get(\"https://internshala.com/jobs/software-development-jobs/\",headers=headers)\n",
    "data=[]\n",
    "if res.status_code==200:\n",
    "    soup = BeautifulSoup(res.content, 'html.parser')\n",
    "    # print(soup.prettify())\n",
    "    jobs=soup.find_all('div',class_='internship_meta')\n",
    "    # print('---',jobs)\n",
    "    for i in jobs:\n",
    "        # print(i)\n",
    "        title=i.find('h3',class_='heading_4_5 profile').get_text().strip()\n",
    "        company_name=i.find('div',class_='heading_6 company_name').get_text().strip()\n",
    "        location=i.find('p',id='location_names').get_text().strip()\n",
    "        data.append({\n",
    "            'title':title,\n",
    "            'company':company_name,\n",
    "            'location':location\n",
    "        })\n",
    "\n",
    "\n",
    "for i in data:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Scrape data from a website and store it in a JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://in.indeed.com/jobs?q=&l=Ahmedabad%2C+Gujarat&from=searchOnHP&vjk=a171eb8abeb40eee\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import json\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "}\n",
    "\n",
    "\n",
    "res = requests.get(\"https://internshala.com/jobs/software-development-jobs/\",headers=headers)\n",
    "data=[]\n",
    "if res.status_code==200:\n",
    "    soup = BeautifulSoup(res.content, 'html.parser')\n",
    "    # print(soup.prettify())\n",
    "    jobs=soup.find_all('div',class_='internship_meta')\n",
    "    # print('---',jobs)\n",
    "    for i in jobs:\n",
    "        # print(i)\n",
    "        title=i.find('h3',class_='heading_4_5 profile').get_text().strip()\n",
    "        company_name=i.find('div',class_='heading_6 company_name').get_text().strip()\n",
    "        location=i.find('p',id='location_names').get_text().strip()\n",
    "        data.append({\n",
    "            'title':title,\n",
    "            'company':company_name,\n",
    "            'location':location\n",
    "        })\n",
    "\n",
    "\n",
    "# save to json\n",
    "with open('jobs.json','w') as f:\n",
    "    json.dump(data,f,indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scrape data from a website and store it in a SQLite database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import sqlite3\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "}\n",
    "\n",
    "\n",
    "res = requests.get(\"https://internshala.com/jobs/software-development-jobs/\",headers=headers)\n",
    "data=[]\n",
    "if res.status_code==200:\n",
    "    soup = BeautifulSoup(res.content, 'html.parser')\n",
    "    # print(soup.prettify())\n",
    "    jobs=soup.find_all('div',class_='internship_meta')\n",
    "    # print('---',jobs)\n",
    "    for i in jobs:\n",
    "        # print(i)\n",
    "        title=i.find('h3',class_='heading_4_5 profile').get_text().strip()\n",
    "        company_name=i.find('div',class_='heading_6 company_name').get_text().strip()\n",
    "        location=i.find('p',id='location_names').get_text().strip()\n",
    "        data.append({\n",
    "            'title':title,\n",
    "            'company':company_name,\n",
    "            'location':location\n",
    "        })\n",
    "\n",
    "\n",
    "# save to sqlite\n",
    "def save_to_sqlite(data, db_name='jobs.db'):\n",
    "    conn = sqlite3.connect(db_name)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    cursor.execute('''\n",
    "        CREATE TABLE IF NOT EXISTS job_listings (\n",
    "            id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "            title TEXT,\n",
    "            company TEXT,\n",
    "            location TEXT\n",
    "        )\n",
    "    ''')\n",
    "    formatted_data = [(item['title'], item['company'], item['location']) for item in data]\n",
    "\n",
    "    cursor.executemany('''\n",
    "        INSERT INTO job_listings (title, company, location)\n",
    "        VALUES (?, ?, ?)\n",
    "    ''', formatted_data)\n",
    "\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "\n",
    "save_to_sqlite(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'title': 'Java Developer', 'company': 'AskMeOffers', 'location': 'Work from home'}, {'title': 'Artificial Intelligence (AI) Associate', 'company': 'AskMeOffers', 'location': 'Work from home'}, {'title': 'Software Developer', 'company': 'AskMeOffers', 'location': 'Work from home'}, {'title': 'C/C++ Developer', 'company': 'AskMeOffers', 'location': 'Work from home'}, {'title': 'SAP BASIS', 'company': 'AskMeOffers', 'location': 'Work from home'}, {'title': '.NET Developer', 'company': 'AskMeOffers', 'location': 'Work from home'}, {'title': 'Java Developer', 'company': 'AskMeOffers', 'location': 'Work from home'}, {'title': 'Software Developer', 'company': 'Home Shiksha', 'location': 'Hyderabad                                            (Hybrid)'}, {'title': 'Junior Software Developer', 'company': 'Transasia Bio Medicals Limited', 'location': 'Mumbai, Pune'}, {'title': 'UI/ UX Designer', 'company': 'MAZIK TECH SOLUTIONS PRIVATE LIMITED', 'location': 'Hyderabad'}, {'title': 'Head Of Engineering', 'company': 'HyrEzy Talent Solutions LLP', 'location': 'Bangalore'}, {'title': 'DevOps And Blockchain', 'company': 'Mazenet Solution', 'location': 'Chennai, Delhi, Pune'}, {'title': 'SFCC Backend Architect', 'company': 'Toolify Private Limited', 'location': 'Gurgaon, Pune, Hyderabad, Noida'}, {'title': 'SFCC Backend Architect', 'company': 'Toolify Private Limited', 'location': 'Hyderabad, Noida, Pune, Gurgaon'}, {'title': 'SFCC Backend Architect', 'company': 'Toolify Private Limited', 'location': 'Noida, Hyderabad, Pune, Gurgaon'}, {'title': 'PFMEA & AIAG - VDA Latest Version', 'company': 'Mazenet Solution', 'location': 'Noida'}, {'title': 'Tibco Flogo', 'company': 'Mazenet Solution', 'location': 'Chennai, Delhi, Bangalore'}, {'title': 'Cisco DNA & Aruba', 'company': 'Mazenet Solution', 'location': 'Chennai, Delhi, Pune, Hyderabad, Bangalore'}, {'title': 'Cybersecurity Trainers Or Consultant', 'company': 'Mazenet Solution', 'location': 'Palghar, Thane, Mumbai'}, {'title': 'Freelance GitHub Trainer', 'company': 'Irizpro Learning Solution', 'location': 'Thane, Mumbai'}, {'title': 'Sr Power Platform Development Architect', 'company': 'True Blue HR Consultants', 'location': 'Bangalore'}, {'title': 'Oracle Cloud Infrastructure Manager', 'company': 'Informica Solutions', 'location': 'Bangalore'}, {'title': 'Full-Stack Development', 'company': 'Toolify Private Limited', 'location': 'Work from home'}, {'title': 'AI/ML Manager', 'company': 'Vs Placement Services', 'location': 'Work from home'}, {'title': 'Java Technical Lead', 'company': 'HRM INFO', 'location': 'Pune, Bangalore'}, {'title': 'Technical Program Manager', 'company': 'Career Fair Services & Technology', 'location': 'Work from home'}, {'title': 'Java Microservices', 'company': 'VIBRANT STAFFING SOLUTIONS PVT LTD', 'location': 'Chennai'}, {'title': 'Data Scientist', 'company': 'Mazenet Solution', 'location': 'Pune'}, {'title': 'Mulesoft Architect', 'company': 'Prointegrate', 'location': 'Bangalore'}, {'title': 'GM- IT ERP- Mumbai', 'company': 'Corporate Chemistry', 'location': 'Mumbai'}, {'title': 'Windchill Solutions Architect', 'company': 'Vizlogic Digital Solutions Private Limited', 'location': 'Chennai, Mumbai'}, {'title': 'Solutions Architect', 'company': 'Vs Placement Services', 'location': 'Work from home'}, {'title': 'Product Manager - Bangalore', 'company': 'True Blue HR Consultants', 'location': 'Bangalore'}, {'title': 'Solutions Architect', 'company': 'Career Fair Services & Technology', 'location': 'Work from home'}, {'title': 'Solutions Architect', 'company': 'Career Fair Services & Technology', 'location': 'Work from home'}, {'title': 'Sr Azure Infrastructure Architect - 15+ Years', 'company': 'True Blue HR Consultants', 'location': 'Bangalore'}, {'title': 'SAP S4 HANA SD Consultant And Project Lead', 'company': 'VIBRANT STAFFING SOLUTIONS PVT LTD', 'location': 'Bangalore'}, {'title': 'Tehcnilca Program Manager', 'company': 'Vs Placement Services', 'location': 'Work from home'}, {'title': 'Information Technology Security Engineer', 'company': 'Informica Solutions', 'location': 'Bangalore'}, {'title': 'Digital Infrastructure Head', 'company': 'Spring HR', 'location': 'Ahmedabad, Gandhinagar, Jamnagar, Vadodara'}]\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
